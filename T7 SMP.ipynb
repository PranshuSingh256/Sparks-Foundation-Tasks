{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRIP TASK: Spark Foundation-April 2023 (Data Science and Business Analytics Intern)\n",
    "## Name: Pranshu Singh\n",
    "Task 7: Stock Market Prediction using Numerical and Textual Analysis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In this task, we have to create the Decision Tree classifier and visualize it graphically using the Iris - dataset. The purpose is if we feed any new data to this classifier, it would be able to predict the right class accordingly.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "* 1 - Importing the dataset\n",
    "* 2 - Preparing Data\n",
    "* 3 - Visualizing the dataset\n",
    "* 4 - Decision Tree Model Training\n",
    "* 5 - Visualizing Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings as wg\n",
    "wg.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost\n",
    "import lightgbm\n",
    "from pandas_datareader.data import DataReader\n",
    "from datetime import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Category</th>\n",
       "      <th>News</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <td>Close</td>\n",
       "      <td>Adj Close</td>\n",
       "      <td>Volume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17</th>\n",
       "      <th>41052.359375</th>\n",
       "      <th>41401.648438</th>\n",
       "      <th>41005.179688</th>\n",
       "      <td>41352.171875</td>\n",
       "      <td>41352.171875</td>\n",
       "      <td>19000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18</th>\n",
       "      <th>41442.750000</th>\n",
       "      <th>41614.769531</th>\n",
       "      <th>41358.468750</th>\n",
       "      <td>41558.570313</td>\n",
       "      <td>41558.570313</td>\n",
       "      <td>24300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19</th>\n",
       "      <th>41571.820313</th>\n",
       "      <th>41719.289063</th>\n",
       "      <th>41456.398438</th>\n",
       "      <td>41673.921875</td>\n",
       "      <td>41673.921875</td>\n",
       "      <td>33300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20</th>\n",
       "      <th>41746.199219</th>\n",
       "      <th>41809.960938</th>\n",
       "      <th>41636.109375</th>\n",
       "      <td>41681.539063</td>\n",
       "      <td>41681.539063</td>\n",
       "      <td>33600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           Date      Category   \n",
       "Date       Open         High         Low                  Close     Adj Close  \\\n",
       "2019-12-17 41052.359375 41401.648438 41005.179688  41352.171875  41352.171875   \n",
       "2019-12-18 41442.750000 41614.769531 41358.468750  41558.570313  41558.570313   \n",
       "2019-12-19 41571.820313 41719.289063 41456.398438  41673.921875  41673.921875   \n",
       "2019-12-20 41746.199219 41809.960938 41636.109375  41681.539063  41681.539063   \n",
       "\n",
       "                                                     News  \n",
       "Date       Open         High         Low           Volume  \n",
       "2019-12-17 41052.359375 41401.648438 41005.179688   19000  \n",
       "2019-12-18 41442.750000 41614.769531 41358.468750   24300  \n",
       "2019-12-19 41571.820313 41719.289063 41456.398438   33300  \n",
       "2019-12-20 41746.199219 41809.960938 41636.109375   33600  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=['Date','Category','News']\n",
    "ndf = pd.read_csv(\"T7_data.csv\",names=columns)\n",
    "ndf.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.drop(0, inplace=True)\n",
    "ndf.drop('Category', axis = 1, inplace=True)\n",
    "print('Showing part of the whole dataset:')\n",
    "ndf.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisdf = pd.read_csv(\"^BSESN.csv\")\n",
    "hisdf.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf[\"Date\"] = pd.to_datetime(ndf[\"Date\"],format='%Y%m%d')\n",
    "ndf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf['News'] = ndf.groupby(['Date']).transform(lambda x : ' '.join(x)) \n",
    "ndf = ndf.drop_duplicates() \n",
    "ndf.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisdf=hisdf[[\"Date\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]]\n",
    "hisdf.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisdf[\"Date\"]= pd.to_datetime(hisdf[\"Date\"])\n",
    "hisdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisdf.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hisdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "hisdf['Close'].plot()\n",
    "plt.ylabel('BSESN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.replace(\"[^a-zA-Z']\",\" \",regex=True,inplace=True)\n",
    "ndf[\"News\"].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = hisdf['Close']\n",
    "\n",
    "ma = close.rolling(window = 50).mean()\n",
    "std = close.rolling(window = 50).std()\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "hisdf['Close'].plot(color='g',label='Close')\n",
    "ma.plot(color = 'r',label='Rolling Mean')\n",
    "std.plot(label = 'Rolling Standard Deviation')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = close / close.shift(1) - 1\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "returns.plot(label='Return', color = 'g')\n",
    "plt.title(\"Returns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = hisdf[:1219]\n",
    "test = hisdf[1219:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationarity(timeseries):\n",
    "\n",
    " #Determine the rolling statistics\n",
    " rolmean = timeseries.rolling(20).mean()\n",
    " rolstd = timeseries.rolling(20).std()\n",
    "\n",
    " #Plot rolling statistics:\n",
    " plt.figure(figsize = (20,10))\n",
    " plt.plot(timeseries, color = 'blue', label = 'original')\n",
    " plt.plot(rolmean, color = 'r', label = 'rolling mean')\n",
    " plt.plot(rolstd, color = 'black', label = 'rolling std')\n",
    " plt.xlabel('Date')\n",
    " plt.legend()\n",
    " plt.title('Rolling Mean and Standard Deviation',  fontsize = 30)\n",
    " plt.show(block = False)\n",
    " \n",
    " print('Results of dickey fuller test')\n",
    " result = adfuller(timeseries, autolag = 'AIC')\n",
    " labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n",
    " for value,label in zip(result, labels):\n",
    "   print(label+' : '+str(value) )\n",
    " if result[1] <= 0.05:\n",
    "   print(\"Strong evidence against the null hypothesis(Ho), reject the null hypothesis. Data is stationary\")\n",
    " else:\n",
    "   print(\"Weak evidence against null hypothesis, time series is non-stationary \")\n",
    "test_stationarity(train['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log = np.log(train['Close']) \n",
    "test_log = np.log(test['Close'])\n",
    "\n",
    "mav = train_log.rolling(24).mean() \n",
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(train_log) \n",
    "plt.plot(mav, color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log.dropna(inplace = True)\n",
    "test_log.dropna(inplace = True)\n",
    "\n",
    "test_stationarity(train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log_diff = train_log - mav\n",
    "train_log_diff.dropna(inplace = True)\n",
    "\n",
    "test_stationarity(train_log_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima\n",
    "model = auto_arima(train_log, trace = True, error_action = 'ignore', suppress_warnings = True)\n",
    "model.fit(train_log)\n",
    "predictions = model.predict(periods = len(test))\n",
    "predictions = pd.DataFrame(predictions,index = test_log.index,columns=['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_log, label='Train')\n",
    "plt.plot(test_log, label='Test')\n",
    "plt.plot(predictions, label='Prediction')\n",
    "plt.title('BSESN Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Actual Stock Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = np.sqrt(mean_squared_error(test_log,predictions))\n",
    "print(\"RMSE : \", rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSubjectivity(text):\n",
    "  return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "def getPolarity(text):\n",
    "  return  TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf['Subjectivity'] = ndf['News'].apply(getSubjectivity)\n",
    "ndf['Polarity'] = ndf['News'].apply(getPolarity)\n",
    "ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "ndf['Compound'] = [sia.polarity_scores(v)['compound'] for v in ndf['News']]\n",
    "ndf['Negative'] = [sia.polarity_scores(v)['neg'] for v in ndf['News']]\n",
    "ndf['Neutral'] = [sia.polarity_scores(v)['neu'] for v in ndf['News']]\n",
    "ndf['Positive'] = [sia.polarity_scores(v)['pos'] for v in ndf['News']]\n",
    "ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(hisdf, ndf, how='inner', on='Date')\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerge1 = df_merge[['Close','Subjectivity', 'Polarity', 'Compound', 'Negative', 'Neutral', 'Positive']]\n",
    "dfmerge1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "df = pd.DataFrame(scaler.fit_transform(dfmerge1))\n",
    "df.columns = dfmerge1.columns\n",
    "df.index = dfmerge1.index\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Close',axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df['Close']\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state = 0)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(x_train, y_train)\n",
    "prediction=rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction[:10])\n",
    "print(y_test[:10])\n",
    "print('Mean Squared error: ',mean_squared_error(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(x_train, y_train)\n",
    "predictions = dtr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions[:10])\n",
    "print(y_test[:10])\n",
    "print('Mean Squared error: ',mean_squared_error(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb = AdaBoostRegressor()\n",
    "adb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = adb.predict(x_test)\n",
    "print(mean_squared_error(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lightgbm.LGBMRegressor()\n",
    "gbm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gbm.predict(x_test)\n",
    "print(mean_squared_error(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBRegressor()\n",
    "xgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = xgb.predict(x_test)\n",
    "print(mean_squared_error(predictions, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff4b1fca65a764b45acb559e482afe389d289dd599b9f8c5fd12ff5c2ea46a65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
